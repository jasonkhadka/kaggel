{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task : To identify if an image shows a healthy cassava leaf or does it shoe an unhealthy leaf with particular disease\nInput: 21397 RGB images with 800x600 resolution\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os, sys\n\n\nDATA_DIR = \"../input/cassava-leaf-disease-classification/\"\nos.listdir(DATA_DIR)\n\npytorch_image_model_path = \"../input/pytorchimagemodels/pytorch-image-models-master\"\n\nsys.path.append(pytorch_image_model_path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from PIL import Image\nimport torch\nimport torchvision\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport timm\n\nimport pandas as pd\nimport numpy as np\nimport random\n\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nimport json\n\nimport time\n\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.backends.cudnn.enabled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Configs"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label = DATA_DIR+\"train.csv\"\nlabel_mapping = DATA_DIR+\"label_num_to_disease_map.json\"\ntrain_images = DATA_DIR+\"train_images/\"\nvalidate_images = DATA_DIR+\"test_images/\"\npredicted_label = DATA_DIR+\"predictions.csv\"\n\nkaggle_model_path = \"/kaggle/working/model_%s_fold_%d_epoch_%d.pth\"\n\nkaggle_trained_weights = \"/kaggle/input/trained-weights-cassava-challenge-2/model_%s_fold_%d_epoch_%d.pth\"\n\n\ninput_size = 512\nseed = 320\nbatch_size_train = 16\nbatch_size_test = 32\nnum_workers = 4\ntest_data_size = 0.02\n\nnum_epoch = [14,14,12]\nnum_of_folds = 3\nnum_classes = 5\naccum_iter = 2\n\nlr = 1e-4\nweight_decay = 1e-6\n\n\nmodel_architecture = 'tf_efficientnet_b3_ns'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Validation images : There is only 1 validation image given. Rest will be shown only after submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_image_list = os.listdir(validate_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (4,4))\n\nax = fig.add_subplot(1, 1, 1)\nax.imshow(Image.open(validate_images+validation_image_list[0]))\nax.set_xticks([])\nax.set_yticks([])\n\nfig.tight_layout()\nfig.suptitle(\"Validation Image\")\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparation of Dataset\n### Train/Validation image augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_train_transforms():\n    return Compose([\n            RandomResizedCrop(input_size, input_size),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            CoarseDropout(p=0.5),\n            Cutout(p=0.5),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n  \n        \ndef get_valid_transforms():\n    return Compose([\n            CenterCrop(input_size, input_size, p=1.),\n            Resize(input_size,input_size),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassavaDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, df, data_dir, transformations = None, output_labels = True):\n        \"\"\"\n            df: dataframe\n            data_dir: directory where images are stored\n            transformations: transformations applied to images\n            output_labels: to output labels or not \n        \"\"\"\n        super().__init__()\n        self.df = df.copy()\n        self.transformations = transformations\n        self.data_dir = data_dir\n        self.output_labels = output_labels\n        if self.output_labels:\n            self.labels = df[\"label\"].values\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        img = np.asarray(Image.open(self.data_dir+self.df.loc[index][\"image_id\"]))\n        if self.transformations:\n            img = self.transformations(image = img)[\"image\"]\n        if self.output_labels:\n            return img, self.labels[index]\n        else:\n            return img\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Designing the model and supplementary functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassavaClassifier(nn.Module):\n    def __init__(self, model_architecture, n_class, pretrained = False):\n        super().__init__()\n        self.model = timm.create_model(model_architecture, pretrained = pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, n_class)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize_network(device, pretrained = False, parameter = None):\n    model = CassavaClassifier(model_architecture, num_classes, pretrained = pretrained).to(device)\n    \n    if parameter:\n        model.load_state_dict(torch.load(parameter))\n    \n    optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = weight_decay)\n    scaler = GradScaler()\n    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.95)\n    \n    return model, optimizer, scaler, exp_lr_scheduler\n\ndef set_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\ndef fold_progressbar(fold, num_of_fold, charlen = 20):\n    fold += 1\n    print(f\"Fold :|{'#'*int(fold/num_of_fold*charlen)}{' '*int((1-fold/num_of_fold)*charlen)}| \\t{fold}/{num_of_fold}\")\n\ndef get_validation_dataloader(validate_images):\n\n    # making validation dataset\n    df_validation = pd.DataFrame()\n    df_validation[\"image_id\"] = list(os.listdir(validate_images)) \n\n    validation_dataset = CassavaDataset(df_validation, validate_images,\n                                        transformations = get_train_transforms(),\n                                        output_labels = False\n                                        )\n    validation_loader = torch.utils.data.DataLoader(validation_dataset, \n                                                   batch_size = batch_size_test,\n                                                   num_workers = num_workers,\n                                                    shuffle = False, \n                                                    pin_memory = False\n                                                   )\n    return df_validation, validation_loader\n\n\ndef get_dataloader(df, train_idx, test_idx, data_dir, transformations, shuffle = True):\n    \"\"\"\n    df: total input dataset containg image filename and target labels\n    train_idx: indices for train data\n    test_idx: indices for test data\n    data_dir: directory for the images\n    \"\"\"\n    \n    df_train = df.loc[train_idx].reset_index(drop=True)\n    df_test = df.loc[test_idx].reset_index(drop=True)\n    \n    train_dataset = CassavaDataset(df_train, data_dir, transformations, output_labels = True)\n    test_dataset = CassavaDataset(df_test, data_dir, transformations, output_labels = True)\n    \n    train_loader = torch.utils.data.DataLoader(train_dataset, \n                                               batch_size = batch_size_train,\n                                               pin_memory = False, \n                                               shuffle = shuffle,\n                                               num_workers = num_workers\n                                               )\n    test_loader = torch.utils.data.DataLoader(test_dataset, \n                                               batch_size = batch_size_test,\n                                               pin_memory = False, \n                                               shuffle = shuffle,\n                                               num_workers = num_workers\n                                               )\n    \n    return train_loader, test_loader\n\n\ndef test_one_epoch(epoch, model, loss_func, test_loader, device,\n                  scheduler = None, scheduler_update = False, loss_array = None):\n    \n    # evaluate model\n    model.eval()\n    \n    fold_prediction_tensor = torch.tensor([])\n    \n    loss_sum = 0\n    total_images = 0\n    total_correct = 0\n    \n    progressbar = tqdm(enumerate(test_loader), total=len(test_loader))\n    \n    for step, (images, image_labels) in progressbar:\n        images = images.to(device).float()\n        image_labels = image_labels.to(device).long()\n        \n        image_preds = model(images)\n        \n        loss = loss_func(image_preds, image_labels)\n        \n        fold_prediction_tensor = torch.cat((fold_prediction_tensor, image_preds.detach().cpu()))\n        \n        image_preds = image_preds.detach().cpu().data.max(1, keepdim=True)[1]\n        image_labels = image_labels.detach().cpu()\n        \n        correct = image_preds.eq(image_labels.view_as(image_preds)).sum()\n        \n        loss_sum += loss\n        total_images += image_labels.shape[0]\n        total_correct += correct\n        \n        progressbar.set_description(f\"Test epoch {epoch} \\tloss:{loss:.4f} \\t accuracy:{correct/image_labels.shape[0]}\")\n        \n        images.detach().cpu()\n        image_labels.detach().cpu()\n        \n    \n    print(\"Test accuracy = {:.4f} \\t  {:d}/{:d}\".format(total_correct/total_images,\n                                                                total_correct,\n                                                                total_images))\n    return fold_prediction_tensor\n        \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(train_label)\n\ntrain_idx = df_train.index\n\nprint(\"Number of examples : \", df_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_predictions_tensor = torch.zeros(len(train_idx), num_classes)\n\n# Inferencing\nfor fold, epoch in zip(range(num_of_folds), num_epoch):\n    \n    set_seed(seed)\n    \n    fold_progressbar(fold, num_of_folds)\n    \n    # validation data loader\n    train_loader, test_loader = get_dataloader(df_train, train_idx, train_idx, train_images, \n                                               get_train_transforms(), shuffle = False)\n    \n    # creating model\n    model, optimizer, scaler, scheduler = initialize_network(device, \n                                        parameter=kaggle_trained_weights%(model_architecture,fold,epoch))\n    \n    # Loss func\n    loss_func = nn.CrossEntropyLoss().to(device)\n    \n    # Inference\n    with torch.no_grad():\n        fold_prediction_tensor = test_one_epoch(epoch, model, loss_func, test_loader, \n                                                device)\n    \n    sum_predictions_tensor = sum_predictions_tensor + fold_prediction_tensor\n    \n    df_train[\"prediction_label_fold_%d\"%(fold+1)] = fold_prediction_tensor.detach().cpu().data.max(1)[1].tolist()\n    \n    del model, optimizer, test_loader, train_loader, scaler, scheduler\n    torch.cuda.empty_cache()\n\nsum_predictions_tensor = sum_predictions_tensor.detach().cpu().data.max(1)[1].tolist()\n\ndf_train[\"prediction_label_sum\"] = sum_predictions_tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicted labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"col_list = ['label','prediction_label_fold_1','prediction_label_fold_2', 'prediction_label_fold_3','prediction_label_sum']\n\nfig = plt.figure(1, figsize=(4,2*len(col_list)))\nfor idx, col in enumerate(col_list):\n    ax = fig.add_subplot(len(col_list), 1, idx+1)\n    ax.hist(df_train[col])\n    \n    ax.set_title(col)\n\nfig.tight_layout()\n\nfig.suptitle(\"Predicted labels\", y = 1.02)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Wrong labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_col_list = ['prediction_label_fold_1','prediction_label_fold_2', 'prediction_label_fold_3','prediction_label_sum']\n\nfig = plt.figure(1, figsize=(4,2*len(prediction_col_list)))\nfor idx, col in enumerate(prediction_col_list):\n    ax = fig.add_subplot(len(col_list), 1, idx+1)\n    df_failed = df_train[~(df_train[\"label\"] == df_train[col])][\"label\"]\n    ax.hist(df_failed)\n    \n    ax.set_title(col)\n\nfig.tight_layout()\nfig.suptitle(\"Wrong labels\", y = 1.02)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Validating the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.to_csv(\"train_results.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}